import logging
from dataclasses import dataclass
from typing import List

from .gitlab_client import (
    get_merge_request_changes,
    get_commit_diff,
    post_merge_request_comment,
    post_commit_comment,
)
from .llm_client import get_llm_model_name, get_llm_provider_name
from .review_cache import (
    get_cached_review_for_changes,
    put_cached_review_for_changes,
)
from .review_chain import get_review_chain
from .types import GitDiffChange, LLMReviewResult, MergeRequestChangesResponse
from .utils.time_utils import format_seconds
from .llm_monitoring import (
    send_merge_request_llm_error,
    send_merge_request_llm_success,
    send_push_llm_error,
    send_push_llm_success,
)


logger = logging.getLogger(__name__)


@dataclass
class MergeRequestReviewTask:
    project_id: int
    merge_request_iid: int
    gitlab_api_base_url: str
    gitlab_access_token: str


@dataclass
class PushReviewTask:
    project_id: int
    commit_id: str
    gitlab_api_base_url: str
    gitlab_access_token: str


def _build_ai_error_comment(prefix: str, error: Exception) -> str:
    lines: List[str] = [
        prefix,
        "",
        "```text",
        str(error),
        "```",
    ]
    return "\n".join(lines)


def _build_llm_footer(result: LLMReviewResult) -> str:
    provider = result["provider"]
    model = result["model"]
    elapsed = result["elapsed_seconds"]

    elapsed_display = format_seconds(elapsed)

    parts: List[str] = [
        f"provider={provider}",
        f"model={model}",
        f"elapsed={elapsed_display}",
    ]

    input_tokens = result.get("input_tokens")
    output_tokens = result.get("output_tokens")
    total_tokens = result.get("total_tokens")

    if input_tokens is not None:
        parts.append(f"input_tokens={input_tokens}")
    if output_tokens is not None:
        parts.append(f"output_tokens={output_tokens}")
    if total_tokens is not None:
        parts.append(f"total_tokens={total_tokens}")

    return "\n\nGenerated by LLM (" + ", ".join(parts) + ")"


def run_merge_request_review(task: MergeRequestReviewTask) -> None:
    """머지 요청에 대한 AI 코드 리뷰를 수행하고 결과/에러 코멘트를 남긴다."""

    logger.info(
        "Running merge_request review: project_id=%s, mr_id=%s",
        task.project_id,
        task.merge_request_iid,
    )

    mr_changes: MergeRequestChangesResponse = get_merge_request_changes(
        task.gitlab_api_base_url,
        task.gitlab_access_token,
        task.project_id,
        task.merge_request_iid,
    )

    changes: List[GitDiffChange] = mr_changes.get("changes", [])

    provider = get_llm_provider_name()
    model = get_llm_model_name()

    try:
        cached: LLMReviewResult | None = get_cached_review_for_changes(
            provider,
            model,
            changes,
        )
        if cached is not None:
            logger.info(
                "Using cached LLM review result for merge_request: project_id=%s, mr_id=%s",
                task.project_id,
                task.merge_request_iid,
            )
            llm_result = cached
        else:
            review_chain = get_review_chain()
            llm_result = review_chain.invoke(changes)
            put_cached_review_for_changes(
                provider,
                model,
                changes,
                llm_result,
            )
        send_merge_request_llm_success(
            gitlab_api_base_url=task.gitlab_api_base_url,
            project_id=task.project_id,
            merge_request_iid=task.merge_request_iid,
            llm_result=llm_result,
        )

        answer = llm_result["content"] + _build_llm_footer(llm_result)
        post_merge_request_comment(
            task.gitlab_api_base_url,
            task.gitlab_access_token,
            task.project_id,
            task.merge_request_iid,
            answer,
        )
    except Exception as e:  # noqa: BLE001 - 외부 API 호출 래핑을 위해 광범위 예외 처리
        logger.exception(
            "Failed to generate review for merge_request: project_id=%s, mr_id=%s",
            task.project_id,
            task.merge_request_iid,
        )

        send_merge_request_llm_error(
            gitlab_api_base_url=task.gitlab_api_base_url,
            project_id=task.project_id,
            merge_request_iid=task.merge_request_iid,
            provider=provider,
            model=model,
            error=e,
        )
        error_comment = _build_ai_error_comment(
            "AI 코드 리뷰 생성에 실패했습니다. 사람이 직접 리뷰해야 합니다.",
            e,
        )
        try:
            post_merge_request_comment(
                task.gitlab_api_base_url,
                task.gitlab_access_token,
                task.project_id,
                task.merge_request_iid,
                error_comment,
            )
        except Exception:  # noqa: BLE001 - GitLab 코멘트 실패도 로깅만 수행
            logger.exception(
                "Failed to post AI error comment for merge_request: project_id=%s, mr_id=%s",
                task.project_id,
                task.merge_request_iid,
            )


def run_push_review(task: PushReviewTask) -> None:
    """푸시(커밋)에 대한 AI 코드 리뷰를 수행하고 결과/에러 코멘트를 남긴다."""

    logger.info(
        "Running push review: project_id=%s, commit_id=%s",
        task.project_id,
        task.commit_id,
    )

    changes = get_commit_diff(
        task.gitlab_api_base_url,
        task.gitlab_access_token,
        task.project_id,
        task.commit_id,
    )
    provider = get_llm_provider_name()
    model = get_llm_model_name()

    try:
        cached: LLMReviewResult | None = get_cached_review_for_changes(
            provider,
            model,
            changes,
        )
        if cached is not None:
            logger.info(
                "Using cached LLM review result for commit: project_id=%s, commit_id=%s",
                task.project_id,
                task.commit_id,
            )
            llm_result = cached
        else:
            review_chain = get_review_chain()
            llm_result = review_chain.invoke(changes)
            put_cached_review_for_changes(
                provider,
                model,
                changes,
                llm_result,
            )
        send_push_llm_success(
            gitlab_api_base_url=task.gitlab_api_base_url,
            project_id=task.project_id,
            commit_id=task.commit_id,
            llm_result=llm_result,
        )

        answer = llm_result["content"] + _build_llm_footer(llm_result)
        post_commit_comment(
            task.gitlab_api_base_url,
            task.gitlab_access_token,
            task.project_id,
            task.commit_id,
            answer,
        )
    except Exception as e:  # noqa: BLE001 - 외부 API 호출 래핑을 위해 광범위 예외 처리
        logger.exception(
            "Failed to generate review for commit: project_id=%s, commit_id=%s",
            task.project_id,
            task.commit_id,
        )

        send_push_llm_error(
            gitlab_api_base_url=task.gitlab_api_base_url,
            project_id=task.project_id,
            commit_id=task.commit_id,
            provider=provider,
            model=model,
            error=e,
        )
        error_comment = _build_ai_error_comment(
            "AI 코드 리뷰 생성에 실패했습니다. 사람이 직접 리뷰해야 합니다.",
            e,
        )
        try:
            post_commit_comment(
                task.gitlab_api_base_url,
                task.gitlab_access_token,
                task.project_id,
                task.commit_id,
                error_comment,
            )
        except Exception:  # noqa: BLE001 - GitLab 코멘트 실패도 로깅만 수행
            logger.exception(
                "Failed to post AI error comment for commit: project_id=%s, commit_id=%s",
                task.project_id,
                task.commit_id,
            )
